{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA87Oq9e6aWD"
      },
      "source": [
        "# Chihuahua or Muffin\n",
        "This notebook demonstrates how we can use Pytorch to work on an image classification problem. It's designed to be run in colab\n",
        "\n",
        "note: this notebook uses mixed precision to faster the model training. It's modified from chihuahua_muffin_resnet01_simple.\n",
        " Changes include\n",
        "- mixed precision related code\n",
        "- time function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku6RtVDM6aWF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import time\n",
        "# Mixed precision imports (only if CUDA is available)\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda.amp import autocast, GradScaler\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imum2q0_6aWG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETSrPyBjpTK8",
        "outputId": "2e055bf2-4c37-4e76-ad10-6bc0f9f08404"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5rn93qw_ox8",
        "outputId": "ffb30557-fb85-4209-dec5-a518d7f647dc"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxvcHZt-6aWG"
      },
      "source": [
        "# prepare directory and files in colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63oKnPxGAG1S",
        "outputId": "0657fef6-1882-411d-cbda-41a429f9a3dd"
      },
      "outputs": [],
      "source": [
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/porrameth/teach_ai.git\n",
        "!ls\n",
        "%cd /content/teach_ai\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnVvVDuo_Sv2",
        "outputId": "b7adc703-85fb-47b4-cc8e-b6ddeb8fb9d0"
      },
      "outputs": [],
      "source": [
        "%pwd\n",
        "#%cd CodeProj2/02_Learn/pytorch/\n",
        "#!ls chihuahua_muffin/\n",
        "!ls chihuahua_muffin_small2/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlk0inFeYPs9"
      },
      "source": [
        "# dataset and loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX6FGYnq_Sv3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define transformations for image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(255),  # Adjust size as needed  255\n",
        "    transforms.CenterCrop(224),  # Adjust size as needed 224\n",
        "    transforms.RandomHorizontalFlip(), # just try\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "TRAIN ='chihuahua_muffin_small2/train'\n",
        "VAL = 'chihuahua_muffin_small2/val'\n",
        "TEST = 'chihuahua_muffin_small2/mytest'\n",
        "# Create dataset\n",
        "train_data = datasets.ImageFolder(root= TRAIN, transform=transform)\n",
        "val_data = datasets.ImageFolder(root= VAL ,transform=transform)\n",
        "test_data = datasets.ImageFolder(root= TEST  ,transform=transform)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gw1OQyq6aWH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j23IjD3MEy2D",
        "outputId": "b156acc8-dac7-456a-8615-0d350f726668"
      },
      "outputs": [],
      "source": [
        "#classes = train_data.classes\n",
        "#classes\n",
        "val_data.classes\n",
        "val_data.class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leBXNJCpFksZ",
        "outputId": "f197946f-4b72-4452-ce56-2337a0f6a6ce"
      },
      "outputs": [],
      "source": [
        "val_data.samples[-10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtAAL4RE_Sv4"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size,num_workers=2)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size,num_workers=2)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size,num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKxH-WwK_Sv4",
        "outputId": "de58fbc8-d232-409c-858d-161fe9829c4e"
      },
      "outputs": [],
      "source": [
        "len(train_dataloader)\n",
        "val_dataloader.dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dHXF2xe_Sv4",
        "outputId": "95ff093d-091d-4f64-e810-9b52e60bf2eb"
      },
      "outputs": [],
      "source": [
        "for X, y in val_dataloader:\n",
        "    print(f' {X.shape}')\n",
        "    print(f'shape of y {y.shape} {y.dtype} ')\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "G6LbYw9KZPOy",
        "outputId": "0e7dddf2-65d7-4975-a82c-327bf60fc883"
      },
      "outputs": [],
      "source": [
        "img, lab = train_data[1]\n",
        "print(img.shape)\n",
        "lab\n",
        "## plot 3 channels image- need to permute channel to the last dimension\n",
        "img = img/2 +.5\n",
        "plt.imshow((img.permute(1,2,0) * 255).numpy().astype('uint16'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "qvw4Njqs_Sv4",
        "outputId": "8fbada40-1d76-4ff1-fa48-2d4f94e93fe3"
      },
      "outputs": [],
      "source": [
        "# print sample of data\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore', message='not allowed')\n",
        "import random\n",
        "#img , label = train_data[0]\n",
        "#print(img.shape, label)\n",
        "\n",
        "\n",
        "labels = [\n",
        "   \"chihuahua\",\"muffin\"\n",
        "]\n",
        "\n",
        "row,col=3,10\n",
        "fig, ax = plt.subplots(row,col,figsize=(12,6))\n",
        "counter=0\n",
        "size = len(train_data)\n",
        "print(f'size {size}')\n",
        "nums = random.sample(range(size),row*col)\n",
        "#print(f'nums {nums}')\n",
        "for r in range(row):\n",
        "    for c in range(col):\n",
        "\n",
        "        num  = nums[counter]\n",
        "        img , lab = train_data[num]\n",
        "        img= img/2+.5\n",
        "        img_permute = img.permute(1,2,0)\n",
        "        img_permute = (img_permute*255).numpy().astype('uint16')\n",
        "        ax[r,c].imshow(img_permute)\n",
        "        ax[r,c].set_axis_off()\n",
        "\n",
        "        #title = \"(\"+str(lab)+\")\"\n",
        "        ax[r,c].set_title(labels[lab])\n",
        "        counter+=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkhjhiY66aWI"
      },
      "source": [
        "# Model Architecture\n",
        "\n",
        "we are using a technique called transfer-learning in order to increase accuracy and speed up the training time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0reQSqeQ_Sv4",
        "outputId": "12d59185-8b58-41b0-8a28-e0bd88ff55b3"
      },
      "outputs": [],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    #else \"mps\"\n",
        "    #if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#Pre-trained ResNet Model\n",
        "model = models.resnet50(weights=True)\n",
        "model = model.to(device)\n",
        "\n",
        "# Freeze Base Model Parameters\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace Final Classifier Layer\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # Binary classification\n",
        "#print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stz3pMAP6aWI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCtsKy3wIP_s",
        "outputId": "8b495d78-77ec-4fed-e378-77610d6c52e4"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for batch, (xx,yy) in enumerate(val_dataloader):\n",
        "    print(batch, xx.shape,yy.shape)\n",
        "    i+=1\n",
        "    if i == 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckjiQVSE6aWJ"
      },
      "outputs": [],
      "source": [
        "## Method 2\n",
        "#loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "learning_rate = 1e-3\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "def train_one_epoch(epoch_index, tb_writer,training_loader,scaler=None):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "    #print(f'device = {device}')\n",
        "    # we use enumerate(training_loader) instead of iter(training_loader) so that we can track the batch index\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        #labels= labels.unsqueeze(1).float() ## FOR BCELoss\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "        if scaler:\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = loss_fn(outputs,labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            # Make predictions for this batch\n",
        "            #model = model.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute the loss and its gradients\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # Adjust weights\n",
        "            optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 5 == 0:\n",
        "            last_loss = running_loss / 5 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## check cuda\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBu0s6Oz6aWJ",
        "outputId": "93f288db-052b-4cf1-abfd-ecd699e6c3bd"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 9\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "time_total  = 0\n",
        "# Mixed precision scaler (only if CUDA is available)\n",
        "scaler = GradScaler() if torch.cuda.is_available() else None\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # gradient is on\n",
        "    model =model.to(device)\n",
        "    model.train(True)\n",
        "    ## add timer\n",
        "    start_time = time.time()\n",
        "    avg_loss = train_one_epoch(epoch_number, writer,train_dataloader,scaler)\n",
        "\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation\n",
        "    correct=0\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(val_dataloader):\n",
        "\n",
        "            vinputs, vlabels = vdata\n",
        "            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
        "            #vlabels = vlabels.unsqueeze(1).float() ## For BCELoss\n",
        "            \n",
        "            # if scaler:  # If scaler is provided, use mixed precision\n",
        "            #     with autocast():\n",
        "            #         outputs = model(inputs)\n",
        "            #         loss = criterion(outputs, labels)\n",
        "            # else:  # Fallback to full precision\n",
        "            #     outputs = model(inputs)\n",
        "            #     loss = criterion(outputs, labels)\n",
        "            if scaler:\n",
        "                with autocast():\n",
        "                    voutputs = model(vinputs)\n",
        "                    vloss = loss_fn(voutputs, vlabels)\n",
        "            else:\n",
        "                voutputs = model(vinputs)\n",
        "                vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct += (voutputs.argmax(1) == vlabels).type(torch.float).sum().item()\n",
        "\n",
        "    ## calculate time for each epoch\n",
        "    epoch_time = time.time() - start_time\n",
        "    time_total+= epoch_time\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print(f'--correct = {correct}, validation size ={len(val_dataloader.dataset)}')\n",
        "    correct /= len(val_dataloader.dataset)\n",
        "    val_accuracy = 100*correct\n",
        "    print(f'LOSS train {avg_loss} valid {avg_vloss:>8f}  Val Accuracy {(val_accuracy):>0.4f}% Time: {epoch_time:.2f}')\n",
        "    #print(f\"Val Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {avg_vloss:>8f} \\n\")\n",
        "\n",
        "\n",
        "    #test(test_dataloader,model, loss_fn)\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best loss, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        model_path = 'model_{}_{}_{:.0f}'.format(timestamp, epoch_number,round(val_accuracy,2)*100)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1\n",
        "print(f'Total training time = {time_total}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#     time_total+= epoch_time\n",
        "\n",
        "#     avg_vloss = running_vloss / (i + 1)\n",
        "#     print(f'--correct = {correct}, validation size ={len(val_dataloader.dataset)}')\n",
        "#     correct /= len(val_dataloader.dataset)\n",
        "#     val_accuracy = 100*correct\n",
        "#     print(f'LOSS train {avg_loss} valid {avg_vloss:>8f}  Val Accuracy {(val_accuracy):>0.4f}% Time: {epoch_time:.2f}')\n",
        "#     #print(f\"Val Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {avg_vloss:>8f} \\n\")\n",
        "\n",
        "\n",
        "#     #test(test_dataloader,model, loss_fn)\n",
        "#     # Log the running loss averaged per batch\n",
        "#     # for both training and validation\n",
        "#     writer.add_scalars('Training vs. Validation Loss',\n",
        "#                     { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "#                     epoch_number + 1)\n",
        "#     writer.flush()\n",
        "\n",
        "#     # Track best loss, and save the model's state\n",
        "#     if avg_vloss < best_vloss:\n",
        "#         best_vloss = avg_vloss\n",
        "#         model_path = 'model_{}_{}_{:.0f}'.format(timestamp, epoch_number,round(val_accuracy,2)*100)\n",
        "#         torch.save(model.state_dict(), model_path)\n",
        "\n",
        "#     epoch_number += 1\n",
        "# print(f'Total training time = {time_total}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPtdezxN6aWJ",
        "outputId": "3d3f255a-73f9-4214-e33c-6b60f9c7479f"
      },
      "outputs": [],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH6rmo79_Sv5",
        "outputId": "deba1d71-5419-4b89-84cc-8ceff5e67f77"
      },
      "outputs": [],
      "source": [
        "#torch.save(model.state_dict(), \"model_muffin_weights-resnet-medium.pth\")\n",
        "#torch.save(model.state_dict(), \"model_muffin_weights-resnet-big.pth\")\n",
        "torch.save(model.state_dict(), \"model_muffin_weights-resnet-small2.pth\")\n",
        "\n",
        "\n",
        "#torch.save(model.state_dict(), \"model_muffin-s.pth\")\n",
        "print(\"Saved PyTorch Model State to model_muffin_weights-resnet-xxxx.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq-Cd3Gf6aWJ"
      },
      "source": [
        "#Load trained model and use it on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXL3JRemKt5d",
        "outputId": "42e956a0-b2f4-4fc1-c58a-617dcdb705e0"
      },
      "outputs": [],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3ctg4ASHlPd",
        "outputId": "d21b5f18-2570-4588-a057-858729417bb0"
      },
      "outputs": [],
      "source": [
        "#model = Convo().to(device)\n",
        "model1 = models.resnet50(weights =False)\n",
        "num_ftrs = model1.fc.in_features\n",
        "model1.fc = nn.Linear(num_ftrs, 2)\n",
        "#model1.load_state_dict(torch.load(\"model_muffin_weights-resnet.pth\"))\n",
        "#model1.load_state_dict(torch.load(\"model_muffin_weights-resnet-big.pth\"))\n",
        "#model1.load_state_dict(torch.load(\"model_muffin_weights-resnet-medium.pth\"))\n",
        "model1.load_state_dict(torch.load(\"model_muffin_weights-resnet-small2.pth\"))\n",
        "#model1.load_state_dict(torch.load(\"model_20240816_091207_8_8735\"))\n",
        "model1.to(device)\n",
        "model1.eval()\n",
        "print(\"Model loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNo06be16aWJ"
      },
      "outputs": [],
      "source": [
        "def sample_incorrect_images(dataset):\n",
        "    row,col=2,5\n",
        "    counter=0\n",
        "\n",
        "    if len(dataset) >= row*col:\n",
        "        nums = random.sample(range(len(dataset)),row*col)\n",
        "        fig, ax = plt.subplots(row,col,figsize=(12,6))\n",
        "        for r in range(row):\n",
        "            for c in range(col):\n",
        "                #print(f'counter = {counter}')\n",
        "                num = nums[counter]\n",
        "                img , lab, pred = dataset[num]\n",
        "                img = img.to('cpu')\n",
        "                img = img/2 +.5\n",
        "                img_permute = img.permute(1,2,0)\n",
        "                img_permute = (img_permute*255).numpy().astype('uint16')\n",
        "                ax[r,c].imshow(img_permute)\n",
        "                ax[r,c].set_axis_off()\n",
        "\n",
        "                #title = \"(\"+str(lab)+\")\"\n",
        "                ax[r,c].set_title(f'Pred:{labels[pred]}\\nActual:{labels[lab]}')\n",
        "                counter+=1\n",
        "    elif len(dataset) == 1:\n",
        "        img , lab, pred = dataset[0]\n",
        "        img = img.to('cpu')\n",
        "        img = img/2 +.5\n",
        "        img_permute = img.permute(1,2,0)\n",
        "        img_permute = (img_permute*255).numpy().astype('uint16')\n",
        "        plt.imshow(img_permute)\n",
        "        plt.suptitle(f'Pred:{labels[pred]}\\nActual:{labels[lab]}')\n",
        "        plt.axis('off')\n",
        "    else:\n",
        "        print(f'Else: length of incorrect dataset = {len(dataset)}')\n",
        "        fig, ax = plt.subplots(len(dataset),figsize=(15,8))\n",
        "        for idx, data in enumerate(dataset):\n",
        "            #print(f'idx={idx}')\n",
        "            img, lab, pred = data\n",
        "            img = img.to('cpu')\n",
        "            img = img/2 +.5\n",
        "            img_permute = img.permute(1,2,0)\n",
        "            img_permute = (img_permute*255).numpy().astype('uint16')\n",
        "            ax[idx].imshow(img_permute)\n",
        "            ax[idx].set_axis_off()\n",
        "                #title = \"(\"+str(lab)+\")\"\n",
        "            ax[idx].set_title(f'Pred:{labels[pred]}\\nActual:{labels[lab]}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test_testset(model=model1, dataloader=test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    incorrect_preds = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in dataloader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            #target = target.unsqueeze(1).float() ## for BCELoss\n",
        "            output = model(data)\n",
        "            #output = output.unsqueeze(1).float()\n",
        "            test_loss += loss_fn(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            for idx in range(len(data)):\n",
        "                if pred[idx] != target[idx]:\n",
        "                    incorrect_preds.append((data[idx], target[idx], pred[idx]))\n",
        "\n",
        "\n",
        "\n",
        "    test_loss /= len(dataloader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(dataloader.dataset),\n",
        "        100. * correct / len(dataloader.dataset)))\n",
        "    if len(incorrect_preds) > 0:\n",
        "      sample_incorrect_images(incorrect_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLR4U17D6aWJ"
      },
      "outputs": [],
      "source": [
        "#test_testset(model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "O6nC644E6aWJ",
        "outputId": "ac34970d-d580-417e-9bad-467c5999d052"
      },
      "outputs": [],
      "source": [
        "test_testset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8YhQcJTH0OL",
        "outputId": "73fe6e8f-a211-4a73-eec6-0a1d29e52144"
      },
      "outputs": [],
      "source": [
        "test_data[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRAaYN5PH99v",
        "outputId": "c4969ecb-9f63-4bcb-97d7-e0b3bd0230bf"
      },
      "outputs": [],
      "source": [
        "test_data[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpxUe128IF13"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSkkC_8ILfB3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
